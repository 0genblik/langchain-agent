{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f806a3e",
   "metadata": {},
   "source": [
    "# An introduction to Langchain and Agentic AI\n",
    "\n",
    "## LLM overview\n",
    "- What is an LLM? How does it work? \n",
    "- Prompts & controlling a model (system prompt, user prompt, strategies like few-shot prompting)\n",
    "    - prompt with: available tools, output schema, safety constraints (e.g. what *shouldn't* our model do)\n",
    "\n",
    "## What are chains and agents? \n",
    "- Chain: fixed recipe - pre-designed sequence of steps. \n",
    "    - Decide ahead of time how this flow works, there is no branching or decision-making by the model. \n",
    "    - RAG:\n",
    "        1. Split a long doc into chunks\n",
    "        2. Compute embeddings \n",
    "        3. For a query, we compute the top-k most relevant chunks \n",
    "        4. Feed the chunks and the query to the LLM\n",
    "        5. Produce some summary or answer \n",
    "    - We know in advance exactly which tools get used, in what order. \n",
    "- Agent: run-time decision-making \n",
    "    - more flexible \n",
    "    - model that decides what tool to use based on what it has learnt so far. \n",
    "    - reason -> act (e.g. call a tool) -> observation (model sees observation from tool) -> reasons again (loop)\n",
    "\n",
    "**ReAct loop:**\n",
    "1. Reason - given what we know, what is the next best action?\n",
    "2. Act - call a tool, or even answer now. \n",
    "3. Observe - read the tool's output \n",
    "4. Repeat\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
